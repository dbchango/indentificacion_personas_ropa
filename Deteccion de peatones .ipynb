{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk \n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "# importamos las librerias\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image as imagePIL\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import lbp\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "def deteccion_facilal(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceClassif.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        frame = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # path del modelo entrenado\n",
    "    modelo_path = 'modelo_multiclase.h5'\n",
    "    video_path =path_video\n",
    "    # path clases\n",
    "    classes_path = 'clases_multiclases.txt'\n",
    "    # cargamos las clases guardadas en el archivo classes.txt\n",
    "    classes = np.loadtxt(classes_path, dtype=np.str)\n",
    "    # instanciamos la fuente para el texto que se mostrara al identificar a una persona\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    # traemos el video que analizaremos\n",
    "    ########video = cv2.VideoCapture(video_path)#####cap\n",
    "    # cargamos el modelo pre - entrenado\n",
    "    our_model = keras.models.load_model(modelo_path)\n",
    "    scale = 1.0\n",
    "    # cargamos el modelo HOGDescriptor\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    # cargamos los pesos para detectar personas en una imagen\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    # contador de frames\n",
    "    count = 0\n",
    "    aux = frame.copy()\n",
    "    # resultados de la deteccion de personas en el frame\n",
    "    (rects, weights) = hog.detectMultiScale(frame, winStride=(2, 2), padding=(4, 4), scale=1.05)\n",
    "    idx = 0\n",
    "    \n",
    "    # recorrido del resultado de rects  para dibujar las cajas alrededor de las personas detectas\n",
    "    for (x, y, w, h) in rects:\n",
    "        # presicion de la deteccion\n",
    "        confidence = float((weights[idx]))\n",
    "# se tomara en cuenta la deteccion de una persona en el frame siempre que la exactitud sea mayor a 2.1\n",
    "        if confidence >= 2.1:\n",
    "            # captura de la seccion del frame, donde se ha detectado una persona\n",
    "            body = aux[y:y + h, x:x + w, :]\n",
    "            # transformamos la seccion de la imagen a PIL image\n",
    "            # body = body.resize((100, 100))\n",
    "            # redimensionamos la seccion que contiene a la persona, para poder pasarla a nuestra red\n",
    "            body = image.array_to_img(x=body).resize(size=(100, 100))\n",
    "            plt.imshow(body)\n",
    "            plt.show()\n",
    "            #body = cv2.resize(body, (100, 100))\n",
    "            # tranformamos la imagen a un arreglo\n",
    "            X = image.img_to_array(body)\n",
    "            # expandimos las dimensiones del array\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "            # guardamos esto en un numpy array\n",
    "            images = np.vstack([X])\n",
    "            # hacemos la prediccion para la persona detectada en la imagen\n",
    "            val = our_model.predict(images)\n",
    "            print(val)\n",
    "            _, j = np.where(val == 1)\n",
    "            label = classes[j]\n",
    "            # dibujamos un rectangulo alrededor del peaton detectado\n",
    "            cv2.rectangle(aux, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            # escribimos el nombre de la etiqueta\n",
    "            cv2.putText(aux, \"{}\".format(label), (x, y + 15),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            idx += 1\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "    pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "    # se dibujan los rectangulos finales\n",
    "    for (xA, yA, xB, yB) in pick:\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "    aux = cv2.cvtColor(aux, cv2.COLOR_BGR2RGB)\n",
    "return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_de_entrada():\n",
    "    global cap, path_video\n",
    "    if selected.get() == 1:\n",
    "        path_video = filedialog.askopenfilename(filetypes = [\n",
    "            (\"all video format\", \".mp4\"),\n",
    "            (\"all video format\", \".avi\")])\n",
    "        if len(path_video) > 0:\n",
    "            btnEnd.configure(state=\"active\")\n",
    "            rad1Ele.configure(state=\"disabled\")\n",
    "            rad2Direc.configure(state=\"disabled\")\n",
    "\n",
    "            pathInputVideo = \"...\" + path_video[-20:]\n",
    "            lblInfoVideoPath.configure(text=pathInputVideo)\n",
    "            cap = cv2.VideoCapture(path_video)\n",
    "            visualizar()\n",
    "    if selected.get() == 2:\n",
    "        btnEnd.configure(state=\"active\")\n",
    "        rad1Ele.configure(state=\"disabled\")\n",
    "        rad2Direc.configure(state=\"disabled\")\n",
    "        lblInfoVideoPath.configure(text=\"\")\n",
    "        cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "        visualizar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar():\n",
    "    global cap\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        frame = imutils.resize(frame, width=640)\n",
    "        frame = deteccion_facilal(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        im = Image.fromarray(frame)\n",
    "        img = ImageTk.PhotoImage(image=im)\n",
    "\n",
    "        lblVideo.configure(image=img)\n",
    "        lblVideo.image = img\n",
    "        lblVideo.after(10, visualizar)\n",
    "    else:\n",
    "        lblVideo.image = \"\"\n",
    "        lblInfoVideoPath.configure(text=\"\")\n",
    "        rad1Ele.configure(state=\"active\")\n",
    "        rad2Direc.configure(state=\"active\")\n",
    "        selected.set(0)\n",
    "        btnEnd.configure(state=\"disabled\")\n",
    "        cap.release()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalizar_limpiar():\n",
    "    lblVideo.image = \"\"\n",
    "    lblInfoVideoPath.configure(text=\"\")\n",
    "    rad1Ele.configure(state=\"active\")\n",
    "    rad2Direc.configure(state=\"active\")\n",
    "    selected.set(0)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "def elegir_imagen():\n",
    "    # Especificar los tipos de archivos, para elegir solo a las imágenes\n",
    "    path_image = filedialog.askopenfilename(filetypes = [\n",
    "        (\"image\", \".jpeg\"),\n",
    "        (\"image\", \".png\"),\n",
    "        (\"image\", \".jpg\")])\n",
    "\n",
    "    if len(path_image) > 0:\n",
    "        global image\n",
    "\n",
    "        # Leer la imagen de entrada y la redimensionamos\n",
    "        image = cv2.imread(path_image)\n",
    "        image= imutils.resize(image, height=380)\n",
    "\n",
    "        # Para visualizar la imagen de entrada en la GUI\n",
    "        imageToShow= imutils.resize(image, width=180)\n",
    "        imageToShow = cv2.cvtColor(imageToShow, cv2.COLOR_BGR2RGB)\n",
    "        im = Image.fromarray(imageToShow )\n",
    "        img = ImageTk.PhotoImage(image=im)\n",
    "    \n",
    "        lblInputImage.configure(image=img)\n",
    "        lblInputImage.image = img\n",
    "        \n",
    "\n",
    "        # Al momento que leemos la imagen de entrada, vaciamos\n",
    "        # la iamgen de salida y se limpia la selección de los\n",
    "        # radiobutton\n",
    "        lblOutputImage.image = \"\"\n",
    "        selected.set(0)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 20,
   "outputs": []
  },
  {
   "source": [
    "def deteccion_color():\n",
    "    global image\n",
    "    if selected.get() == 1:\n",
    "        # Rojo\n",
    "        rangoBajo1 = np.array([0, 140, 90], np.uint8)\n",
    "        rangoAlto1 = np.array([8, 255, 255], np.uint8)\n",
    "        rangoBajo2 = np.array([160, 140, 90], np.uint8)\n",
    "        rangoAlto2 = np.array([180, 255, 255], np.uint8)\n",
    "\n",
    "    if selected.get() == 2:\n",
    "        # Amarillo\n",
    "        rangoBajo = np.array([10, 98, 0], np.uint8)\n",
    "        rangoAlto = np.array([25, 255, 255], np.uint8)\n",
    "\n",
    "    if selected.get() == 3:\n",
    "        # Azul celeste\n",
    "        rangoBajo = np.array([88, 104, 121], np.uint8)\n",
    "        rangoAlto = np.array([99, 255, 243], np.uint8)\n",
    "        \n",
    "    imageGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    imageGray = cv2.cvtColor(imageGray, cv2.COLOR_GRAY2BGR)\n",
    "    imageHSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    if selected.get() == 1:\n",
    "        # Detectamos el color rojo\n",
    "        maskRojo1 = cv2.inRange(imageHSV, rangoBajo1, rangoAlto1)\n",
    "        maskRojo2 = cv2.inRange(imageHSV, rangoBajo2, rangoAlto2)\n",
    "        mask = cv2.add(maskRojo1, maskRojo2)\n",
    "    else:\n",
    "        # Detección para el color Amarillo y Azul celeste\n",
    "        mask = cv2.inRange(imageHSV, rangoBajo, rangoAlto)\n",
    "\n",
    "    mask = cv2.medianBlur(mask, 7)\n",
    "    colorDetected = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Fondo en grises\n",
    "    invMask = cv2.bitwise_not(mask)\n",
    "    bgGray = cv2.bitwise_and(imageGray, imageGray, mask=invMask)\n",
    "\n",
    "    # Sumamos bgGray y colorDetected\n",
    "    finalImage = cv2.add(bgGray, colorDetected)\n",
    "    imageToShowOutput = cv2.cvtColor(finalImage, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Para visualizar la imagen en lblOutputImage en la GUI\n",
    "    im = Image.fromarray(imageToShowOutput)\n",
    "    img = ImageTk.PhotoImage(image=im)\n",
    "    lblOutputImage.configure(image=img)\n",
    "    lblOutputImage.image = img\n",
    "    # Label IMAGEN DE SALIDA\n",
    "    lblInfo3 = Label(win, text=\"IMAGEN DE SALIDA:\", font=\"bold\")\n",
    "    lblInfo3.grid(column=1, row=0, padx=5, pady=5)\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ventana2():\n",
    "    global lblInputImage, lblOutputImage,selected,win\n",
    "\n",
    "    win = tk.Toplevel()\n",
    "    # Label donde se presentará la imagen de entrada\n",
    "    lblInputImage = tk.Label(win)\n",
    "    lblInputImage.grid(column=0, row=2)\n",
    "    # Label donde se presentará la imagen de salida\n",
    "    lblOutputImage = Label(win)\n",
    "    lblOutputImage.grid(column=1, row=1, rowspan=6)\n",
    "\n",
    "    lblInfo2 = Label(win, text=\"Analizar\", width=25)\n",
    "    lblInfo2.grid(column=0, row=3, padx=5, pady=5)\n",
    "    # Label IMAGEN DE ENTRADA\n",
    "    lblInfo1 = tk.Label(win, text=\"IMAGEN DE ENTRADA:\")\n",
    "    lblInfo1.grid(column=0, row=1, padx=5, pady=5)\n",
    "    # Creamos los radio buttons y la ubicación que estos ocuparán\n",
    "    selected = IntVar()\n",
    "    rad1 = Radiobutton(win, text='Rojo', width=25,value=1, variable=selected, command= deteccion_color)\n",
    "    rad2 = Radiobutton(win, text='Amarillo',width=25, value=2, variable=selected, command= deteccion_color)\n",
    "    rad3 = Radiobutton(win, text='Azul celeste',width=25, value=3, variable=selected, command= deteccion_color)\n",
    "    rad1.grid(column=0, row=4)\n",
    "    rad2.grid(column=0, row=5)\n",
    "    rad3.grid(column=0, row=6)\n",
    "    # Creamos el botón para elegir la imagen de entrada\n",
    "    btn = Button(win, text=\"Elegir imagen\", width=25, command=elegir_imagen)\n",
    "    btn.grid(column=0, row=0, padx=5, pady=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ventanaVideo():\n",
    "    global winVideo,lblInfo1Video,btnEleVideo,rad1Ele,rad2Direc,lblInfoVideoPath,lblVideo,btnEnd,selected,lblCapturaImegen\n",
    "\n",
    "    cap = None\n",
    "    winVideo = tk.Toplevel()\n",
    "    ###################################\n",
    "    lblCapturaImegen = Label(winVideo)\n",
    "    lblCapturaImegen.grid(column=100, row=30, columnspan=2)\n",
    "    ###################################\n",
    "\n",
    "\n",
    "    lblInfo1Video = Label(winVideo, text=\"VIDEO DE ENTRADA\", font=\"bold\")\n",
    "    lblInfo1Video.grid(column=0, row=0, columnspan=2)\n",
    "    selected = IntVar()\n",
    "    rad1Ele = Radiobutton(winVideo, text=\"Elegir video\", width=20, value=1, variable=selected, command=video_de_entrada)\n",
    "    rad2Direc = Radiobutton(winVideo, text=\"Video en directo\", width=20, value=2, variable=selected, command=video_de_entrada)\n",
    "    rad1Ele.grid(column=0, row=1)\n",
    "    rad2Direc.grid(column=1, row=1)\n",
    "    lblInfoVideoPath = Label(winVideo, text=\"\", width=20)\n",
    "    lblInfoVideoPath.grid(column=0, row=2)\n",
    "\n",
    "    lblVideo = Label(winVideo)\n",
    "    lblVideo.grid(column=0, row=3, columnspan=2)\n",
    "\n",
    "    btnEnd = Button(winVideo, text=\"Finalizar visualización y limpiar\", state=\"disabled\", command=finalizar_limpiar)\n",
    "    btnEnd.grid(column=0, row=4, columnspan=2, pady=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-16-97edc8b75609>:13: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  classes = np.loadtxt(classes_path, dtype=np.str)\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\miniconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-17-85cb227bf119>\", line 15, in video_de_entrada\n",
      "    visualizar()\n",
      "  File \"<ipython-input-18-986475f894f5>\", line 6, in visualizar\n",
      "    frame = deteccion_facilal(frame)\n",
      "  File \"<ipython-input-16-97edc8b75609>\", line 30, in deteccion_facilal\n",
      "    (rects, weights) = hog.detectMultiScale(frame, winStride=(2, 2), padding=(4, 4), scale=1.05)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-27a68668069b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mbtn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mventana\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[1;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ventana= tk.Tk()\n",
    "\n",
    "ventana.title(\"Sistema\")\n",
    "\n",
    "ventana.geometry('500x500')\n",
    "\n",
    "lbl = Label(ventana, text=\"Sistema para el reconocimiento de personas\")\n",
    "lbl.place(x=70, y=10)\n",
    "\n",
    "lblA = Label(ventana, text=\"Analizar\")\n",
    "lblA.place(x=10, y=70)\n",
    "\n",
    "btnV =Button(ventana, text=\"Video\", command = ventanaVideo)\n",
    "btnV.place(x=90, y=50, width=100, height=30)\n",
    "\n",
    "btn = Button(ventana, text=\"Imagen\", command = ventana2)\n",
    "btn.place(x=90, y=90, width=100, height=30)\n",
    "\n",
    "ventana.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd022bb53b43b3afb0848b0afa27adb8f2415fb61399be88b9ea69bd0b84fe58c05",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}